{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e0f34c",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv('svd_df.csv')\n",
    "y_ = pd.read_csv('tokenized.csv')['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d634357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert classes: 0 remains 0, and 4 becomes 1\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef8853",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08199ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f971dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be9302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse = sqrt(mean_squared_error(y_test,y))\n",
    "\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c0f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the model\n",
    "model = LogisticRegression(solver='saga', max_iter=10000)\n",
    "\n",
    "# Define a grid of parameters to search over\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073bfb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0efebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test, y_)\n",
    "recall = recall_score(y_test, y_)\n",
    "\n",
    "precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ce704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Create an interactive plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Traces\n",
    "fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name='ROC Curve',\n",
    "                         line=dict(color='darkorange'),\n",
    "                         showlegend=True))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Chance',\n",
    "                         line=dict(color='navy', dash='dash'),\n",
    "                         showlegend=False))\n",
    "\n",
    "# Add AUC in the legend\n",
    "fig.update_layout(title=f'ROC Curve (AUC = {roc_auc:.2f})',\n",
    "                  xaxis_title='False Positive Rate',\n",
    "                  yaxis_title='True Positive Rate',\n",
    "                  xaxis=dict(showgrid=False),\n",
    "                  yaxis=dict(showgrid=False),\n",
    "                  template=\"plotly_white\")\n",
    "\n",
    "# Show figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb96c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e0150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model using 'liblinear' solver\n",
    "model = LogisticRegression(solver='saga', random_state=42, max_iter=10000, tol=1e-4)\n",
    "\n",
    "# Define a grid of hyperparameter values to search over\n",
    "param_grid = {\n",
    "    'C': [ 0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l1', 'l2']  # liblinear supports both L1 and L2 regularization\n",
    "}\n",
    "\n",
    "# Define the AUC scoring function\n",
    "auc_scorer = make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=auc_scorer, cv=5, verbose=1)\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# After fitting, you can check the best parameters and the best AUC score\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best AUC score: {grid_search.best_score_}\")\n",
    "\n",
    "# Optionally, evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_ = best_model.predict_proba(X_test)[:, 1]  # Get probability estimates of the positive class\n",
    "test_auc = roc_auc_score(y_test, y_)\n",
    "\n",
    "print(f\"Test AUC score: {test_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd569f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Create an interactive plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add Traces\n",
    "fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name='ROC Curve',\n",
    "                         line=dict(color='darkorange'),\n",
    "                         showlegend=True))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Chance',\n",
    "                         line=dict(color='navy', dash='dash'),\n",
    "                         showlegend=False))\n",
    "\n",
    "# Add AUC in the legend\n",
    "fig.update_layout(title=f'ROC Curve (AUC = {roc_auc:.2f})',\n",
    "                  xaxis_title='False Positive Rate',\n",
    "                  yaxis_title='True Positive Rate',\n",
    "                  xaxis=dict(showgrid=False),\n",
    "                  yaxis=dict(showgrid=False),\n",
    "                  template=\"plotly_white\")\n",
    "\n",
    "# Show figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad40d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d45ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
